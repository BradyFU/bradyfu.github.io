<head>
<link rel="shortcut icon" href="images/z.ico" type="image/x-icon" />
<meta name="keywords" content="Chaoyou Fu" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="style.css" type="text/css" />

<title>Chaoyou Fu-Homepage</title>
</head>
<body>
<div id="layout-content">

<table class="imgtable"><tr><td>
<img src="images/v.jpeg" alt="alt text" width="355.56px" height="200px"/> &nbsp;</td>
<td align="left">

<div id="toptitle"> 
    <h1> Chaoyou Fu &nbsp; <img src="./images/name.png" alt="alt text" height="31"> <br /> </h1> 
</div>

<p>
Senior Researcher
<br />
<a href="https://open.youtu.qq.com/#/open/home"> Tencent Youtu Lab </a> <br />
<br />
<a href="https://scholar.google.com.hk/citations?user=4A1xYQwAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;|&nbsp; <a href="https://github.com/BradyFU">GitHub</a><br />
Email: <img src="./images/email.png" alt="alt text" height="17"> <br />
</p>
</td></tr></table>
<hr />




<h2>Biography</h2>
<p>
I am a senior researcher at Tencent Youtu Lab. Before that, I obtained my Ph.D. degree from <a href="http://www.cripac.ia.ac.cn/CN/model/index.htm">CRIPAC-NLPR-CASIA</a> in 2022, under the leadership of <a href="http://cripac.ia.ac.cn/CN/column/item83.shtml">Prof. Tieniu Tan</a> and the supervision of <a href="http://people.ucas.ac.cn/~heran">Prof. Ran He</a>. I received my B.E. degree from <a href="http://www.ahu.edu.cn/">Anhui University</a> in 2017, where I was advised by <a href="https://scholar.google.com.hk/citations?user=zefmEBwAAAAJ&hl=zh-CN&oi=ao">Prof. Shuping He</a>.
</p>
<br />
<p>
My current research interests mainly focus on biometrics (especially face recognition and generation) and multimodality (especially vision+language).
</p>
<br />
<p>
<span style="color: #black"> <strong> I am open to any discussion or collaboration. If you are interested, please feel free to contact me. </strong> </span> 
</p>




<h2>Selected Publications</h2>
<table class="imgtable"><tr><td>
<img src="images/paper_mllm.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://arxiv.org/pdf/2306.13549.pdf">A Survey on Multimodal Large Language Models</a> <br />
Shukang Yin, <strong>Chaoyou Fu</strong> [Project Leader], Sirui Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen <br />
arXiv 2023, <a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models">Project [5k+ Stars ğŸŒŸ]</a>
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="images/paper_mme.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://arxiv.org/pdf/2306.13394.pdf">MME: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models</a> <br />
<strong>Chaoyou Fu</strong>, Peixian Chen, Yunhang Shen, Yulei Qin, Mengdan Zhang, Xu Lin, et al <br />
arXiv 2023, <a href="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation">Leaderboard [with 25+ MLLMs ğŸŒŸ]</a>
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="images/paper_woodpecker.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://arxiv.org/pdf/2310.16045.pdf">Woodpecker: Hallucination Correction for Multimodal Large Language Models</a> <br />
Shukang Yin, <strong>Chaoyou Fu</strong> [Project Leader], Sirui Zhao, Tong Xu, Hao Wang, Dianbo Sui, Yunhang Shen, Ke Li, Xing Sun, Enhong Chen <br />
arXiv 2023, <a href="https://github.com/BradyFU/Woodpecker">Code</a>
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="images/paper_mqdet.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://arxiv.org/pdf/2305.18980.pdf">Multi-Modal Queried Object Detection in the Wild</a> <br />
Yifan Xu, Mengdan Zhang, <strong>Chaoyou Fu</strong>, Peixian Chen, Xiaoshan Yang, Ke Li, Changsheng Xu <br />
NeurIPS 2023, <a href="https://github.com/YifanXu74/MQ-Det">Code</a>
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="images/paper_dvg-face.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://arxiv.org/pdf/2009.09399.pdf">DVG-Face: Dual Variational Generation for Heterogeneous Face Recognition</a> <br />
<strong>Chaoyou Fu</strong>, Xiang Wu, Yibo Hu, Huaibo Huang, and Ran He <br />
TPAMI 2022, <a href="https://github.com/BradyFU/DVG">Code</a> 
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="images/paper_safe.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://ieeexplore.ieee.org/abstract/document/9971748">Towards Lightweight Pixel-Wise Hallucination for Heterogeneous Face Recognition</a> <br />
<strong>Chaoyou Fu</strong>, Xiaoqiang Zhou, Weizan He, and Ran He <br />
TPAMI 2023
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="images/paper_mvf.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://arxiv.org/pdf/1903.12003.pdf">High Fidelity Face Manipulation with Extreme Poses and Expressions</a> <br />
<strong>Chaoyou Fu</strong>, Yibo Hu, Xiang Wu, Guoli Wang, Qian Zhang, and Ran He <br />
TIFS 2021, <a href="./projects/mvf-hq/mvf-hq.html">Dataset</a>
</p>
</td></tr></table>


<table class="imgtable"><tr><td>
<img src="images/paper_cm-nas.png" alt="alt text" width="120" height="75"/> &nbsp;</td>
<td align="left">
<p> <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Fu_CM-NAS_Cross-Modality_Neural_Architecture_Search_for_Visible-Infrared_Person_Re-Identification_ICCV_2021_paper.pdf">CM-NAS: Cross-Modality Neural Architecture Search for Visible-Infrared Person Re-Identification</a> <br />
<strong>Chaoyou Fu</strong>, Yibo Hu, Xiang Wu, Hailin Shi, Tao Mei, and Ran He <br />
ICCV 2021, <a href="https://github.com/JDAI-CV/CM-NAS">Code</a>
</p>
</td></tr></table>




<h2>Academic Services</h2> 
<ul>
<li><p> Conference Reviewer: NeurIPS, ICLR, ICML, CVPR, ICCV, ECCV, AAAI, ACM MM, IJCAI </p></li>
<li><p> Journal Reviewer: IEEE TIP, PR </p></li>
</ul>




<h2>Honors and Awards</h2> 
<ul>
<li><p> [2023.08] ä¸­å›½ç§‘å­¦é™¢ä¼˜ç§€åšå£«å­¦ä½è®ºæ–‡ </p></li>
<li><p> [2023.07] <span style="color: #4f69c6"><strong>IEEE Biometrics Council Best Doctoral Dissertation Award</strong></span> </p></li>
<li><p> [2023.07] CVPR 2023 Outstanding Reviewer (232/7000+) </p></li>
<li><p> [2022.07] <span style="color: #4f69c6"><strong>ä¸­å›½ç§‘å­¦é™¢é™¢é•¿ç‰¹åˆ«å¥–</strong></span> </p></li>
<li><p> [2022.07] åŒ—äº¬å¸‚ä¼˜ç§€æ¯•ä¸šç”Ÿ </p></li>
<li><p> [2021.12] 2022å¹´â€œ<span style="color: #4f69c6"><strong>é˜¿é‡Œæ˜Ÿ</strong></span>â€è®¡åˆ’ </p></li>
<li><p> [2021.12] åšå£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ </p></li>
<li><p> [2021.11] å®é’¢å¥–å­¦é‡‘ä¼˜ç§€å­¦ç”Ÿå¥– </p></li>
<li><p> [2019.12] ç¡•å£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ </p></li>
<li><p> [2017.06] å®‰å¾½çœä¼˜ç§€æ¯•ä¸šç”Ÿ </p></li>
<li><p> [2015.11] æœ¬ç§‘ç”Ÿå›½å®¶å¥–å­¦é‡‘ </p></li>
<li><p> [2015.08] â€œé£æ€å¡å°”â€æ¯å…¨å›½å¤§å­¦ç”Ÿæ™ºèƒ½æ±½è½¦ç«èµ›å…¨å›½æ€»å†³èµ›äºŒç­‰å¥– </p></li>
</ul>






</body>
</html>


